{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk import parse\n",
    "from nltk.grammar import CFG\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' F_LINE Manhattan-bound platforms at Avenue U Avenue P Avenue N Bay Pkwy  and Avenue I are closed for renovation'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('notes&type.csv')\n",
    "\n",
    "def note_tsf(note):\n",
    "    note = note.replace(',','')\n",
    "    note = note.replace('Av-', 'Av $ ')\n",
    "    return note\n",
    "note = note_tsf(data.iloc[9][0])\n",
    "note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar1 = CFG.fromstring(\"\"\"\n",
    "\n",
    "no_trains -> S1 VP1\n",
    "\n",
    "S1 -> sub1\n",
    "VP1 ->  no_train between stations1\n",
    "\n",
    "no_train -> no train\n",
    "between -> \"between\"\n",
    "stations1 -> from and to\n",
    "\n",
    "from -> stop\n",
    "to -> stop\n",
    "\n",
    "stop -> loc street | loc loc street\n",
    "\n",
    "sub1 -> \"4_LINE\"\n",
    "no -> \"No\"\n",
    "train -> \"trains\"\n",
    "between -> \"between\"\n",
    "and -> \"and\"\n",
    "street -> \"Av\"\n",
    "\n",
    "\n",
    "perform_and_close -> S VP\n",
    "\n",
    "S -> subs direction prep stations\n",
    "VP -> be close prep reason\n",
    "\n",
    "subs -> sub | sub sub | sub sub sub\n",
    "direction -> bound sup\n",
    "stations -> stop | stop and stop | stop stop and stop | stop stop stop stop and stop\n",
    "\n",
    "stop -> Street Letter | Loc Street | Loc Loc Ave |num Street intersect num Street | \n",
    "\n",
    "\n",
    "sub -> \"F_LINE\" |\"Coney\"\n",
    "bound -> \"Manhattan-bound\" | \"Jamaica-bound\" | \"Woodlawn-bound\" | \"Island-bound\"\n",
    "sup -> \"trains\" | \"platforms\"\n",
    "close -> \"closed\"\n",
    "num -> \"25\" | \"75\"| \"161\" | \"167\" | \"170\" | \"176\" | \"4\" | \"9\"\n",
    "Street -> \"St\" | \"Av\" | \"Blvd\" | \"Av- \" | \"Pkwy\" | \"Avenue\"\n",
    "Loc -> \"Union\" | \"Sutphin\" | \"Briarwood\" | \"Mt\" | \"Eden\" | \"Bay\" \n",
    "Letter -> \"U\" | \"P\" | \"N\" | \"I\"\n",
    "Service -> \"service\"\n",
    "and -> \"and\"\n",
    "prep -> \"for\" | \"at\"\n",
    "be -> \"is\" | \"are\"\n",
    "reason -> \"renovation\"\n",
    "intersect -> \"$\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.RecursiveDescentParser(grammar1)\n",
    "tree2 = parser.parse(note.split())\n",
    "a = []\n",
    "for t in tree2:\n",
    "    a.append(t)\n",
    "    t.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'Subways': [],\n",
    "       'Direction': [],\n",
    "       'Status': [],\n",
    "       'Stations': []}\n",
    "\n",
    "for subtree3 in a[0].subtrees():\n",
    "    if subtree3.label() == 'Sub':\n",
    "        #print(subtree3)\n",
    "        sub = subtree3.leaves()\n",
    "        print(sub)\n",
    "        dic['Subways'].append(sub[0])\n",
    "    if subtree3.label() == 'Direction':\n",
    "        direc = subtree3.leaves()\n",
    "        #print(direc)\n",
    "        dic['Direction'].append(direc[0])\n",
    "    if subtree3.label() == 'Status':\n",
    "        stat = subtree3.leaves()\n",
    "        #print(stat)\n",
    "        dic['Status'].append(stat[0])\n",
    "    if subtree3.label() == 'Stations':\n",
    "        for subtree4 in subtree3.subtrees():\n",
    "            if subtree4.label() == 'Stop':\n",
    "                stop = subtree4.leaves()\n",
    "                string = ''\n",
    "                for i in range(len(stop)):\n",
    "                    string +=  ' ' + stop[i]\n",
    "                string = string[1:]\n",
    "                dic['Stations'].append(string)\n",
    "                \n",
    "        \n",
    "        \n",
    "dic\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# note = []\n",
    "# for a in range(len(data)):\n",
    "#     s = data.iloc[a]\n",
    "#     note.append(s[0])\n",
    "#     print (s[0])\n",
    "   \n",
    "# s = []\n",
    "# for i in note:\n",
    "#     i.replace(',', '')\n",
    "#     i.replace('Av-', 'Av $ ')\n",
    "#     s.append(i)\n",
    "    \n",
    "# s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
